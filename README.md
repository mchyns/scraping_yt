# ğŸ¬ YouTube Comment Sentiment Analysis# Analisis Sentimen Komentar YouTube



Sistem analisis sentimen komentar YouTube menggunakan **Machine Learning** dan **Natural Language Processing** untuk Bahasa Indonesia.Sistem analisis sentimen untuk komentar YouTube menggunakan YouTube Data API v3 dengan beberapa metode analisis untuk perbandingan.



---## Fitur



## ğŸ“‹ Daftar Isi- Scraping komentar YouTube menggunakan YouTube Data API v3

- Analisis sentimen dengan 4 metode berbeda:

- [Fitur Utama](#-fitur-utama)  - **Lexicon-Based**: Analisis berbasis kamus kata positif/negatif

- [Metode Analisis](#-metode-analisis)  - **VADER**: Valence Aware Dictionary and sEntiment Reasoner

- [Teknologi](#-teknologi)  - **TextBlob**: Library NLP untuk analisis sentimen

- [Instalasi](#-instalasi)  - **Rule-Based**: Kombinasi beberapa metode dengan aturan kustom

- [Cara Penggunaan](#-cara-penggunaan)- Visualisasi hasil analisis per metode

- [Struktur Project](#-struktur-project)- Tampilan tabel detail komentar

- [API Endpoints](#-api-endpoints)- Export hasil ke format Excel

- [Preprocessing](#-preprocessing)- Interface web dengan Flask

- [Lexicon Database](#-lexicon-database)

## Instalasi

---

1. Clone atau download repository ini

## âœ¨ Fitur Utama

### 1. **Scraping Komentar YouTube**
- Input URL video YouTube
- Scraping otomatis menggunakan YouTube Data API v3
- **Support hingga 100,000 komentar sekaligus** dengan pagination otomatis
- Ambil komentar beserta metadata (likes, replies, author)
- Progress tracking real-time dengan progress bar
- Save data ke JSON untuk analisis ulang
- Optional: Include replies (balasan komentar)
- Deteksi otomatis jumlah komentar tersedia di video

### 2. **Analisis Sentimen Multi-Method**
4 metode machine learning yang berbeda:
- âœ… **Naive Bayes Classifier** - Probabilistic classifier
- âœ… **Support Vector Machine (SVM)** - Linear classification  
- âœ… **LSTM** - Deep learning untuk sekuensial
- âœ… **IndoBERT** - Transformer model untuk Bahasa Indonesia

### 3. **Preprocessing Text Advanced**
12 langkah preprocessing otomatis:
1. Original Text
2. Case Folding (lowercase)

3. Noise Removal (URL, @mentions, #hashtags)http://localhost:5000

4. Remove Numbers```

5. Remove Punctuation

6. Spelling Correction (normalisasi slang)3. Masukkan:

7. Tokenization   - URL video YouTube

8. Normalization (slang â†’ formal)   - Jumlah maksimal komentar yang ingin dianalisis (1-500)

9. Stopword Removal

10. Stemming (root words)4. Klik "Analisis Sentimen"

11. Negation Handling (NOT_ prefix)

12. Final Result5. Lihat hasil analisis:

   - Perbandingan hasil dari 4 metode

### 4. **Visualisasi & Statistik**   - Tabel detail komentar dengan sentimen per metode

- ğŸ“Š Distribusi Sentimen per metode

- ğŸ¯ Confusion Matrix untuk setiap metode6. Klik "Export ke Excel" untuk mengunduh hasil analisis

- ğŸ“ˆ Accuracy Rate (agreement dengan majority voting)

- â˜ï¸ Word Clouds untuk sentimen positif & negatif## Struktur Project



### 5. **Fitur Tambahan**```

- ğŸ’¬ **Quick Analysis**: Analisis cepat single comment di navbaryt_scraping/

- ğŸ“š **History Management**: Simpan & load hasil analisis (localStorage)â”‚

- ğŸ”¬ **Detail Preprocessing**: Modal pop-up step-by-step preprocessingâ”œâ”€â”€ app.py                  # Aplikasi Flask utama

- ğŸ’¾ **Save Analysis**: Export hasil ke JSONâ”œâ”€â”€ youtube_scraper.py      # Module untuk scraping YouTube

- ğŸ“„ **Export Excel**: Download hasil dalam format Excelâ”œâ”€â”€ sentiment_analyzer.py   # Module analisis sentimen

â”œâ”€â”€ requirements.txt        # Dependencies Python

---â”œâ”€â”€ .env                   # Konfigurasi API Key

â”œâ”€â”€ README.md              # Dokumentasi

## ğŸ¤– Metode Analisisâ”‚

â””â”€â”€ templates/

### 1. Naive Bayes Classifier    â””â”€â”€ index.html         # Template HTML untuk interface

- **Training**: 1,200 samples (450 pos + 450 neg + 300 neutral)```

- **Features**: TF-IDF dengan max 2000 features, trigram (1-3)

- **Alpha**: 0.5 (Laplace smoothing)## Metode Analisis Sentimen

- **Lexicon Integration**: Boost confidence dengan lexicon score

### 1. Lexicon-Based

### 2. Support Vector Machine (SVM)Menggunakan kamus kata positif dan negatif dalam bahasa Indonesia dan Inggris untuk menentukan sentimen.

- **Training**: 1,200 balanced samples

- **C Parameter**: 1.5 (regularization)### 2. VADER (Valence Aware Dictionary and sEntiment Reasoner)

- **Class Weight**: BalancedMetode yang dirancang khusus untuk analisis sentimen di media sosial, sangat baik untuk teks informal.

- **Lexicon Boost**: Combine dengan lexicon score

### 3. TextBlob

### 3. LSTM & IndoBERTLibrary NLP yang menggunakan algoritma machine learning untuk analisis sentimen.

- Implementation placeholder (untuk development selanjutnya)

- LSTM: Sequential deep learning### 4. Rule-Based

- IndoBERT: Transformer untuk Bahasa IndonesiaKombinasi dari beberapa metode dengan aturan tambahan seperti deteksi emphasis (tanda seru, huruf kapital).



---## Format Output Excel



## ğŸ›  TeknologiFile Excel yang di-export berisi 2 sheet:

1. **Komentar**: Detail setiap komentar dengan hasil analisis dari 4 metode

### Backend2. **Ringkasan**: Statistik agregat untuk setiap metode

- Python 3.13.5

- Flask 3.0.0## Catatan

- scikit-learn 1.3.2

- numpy 2.2.4- API Key YouTube memiliki quota harian, gunakan dengan bijak

- Sastrawi (Indonesian NLP)- Maksimal 500 komentar per analisis untuk menghindari quota limit

- Beberapa video mungkin menonaktifkan komentar

### Visualization- Analisis sentimen lebih akurat untuk teks dalam bahasa Inggris

- matplotlib 3.10.6

- seaborn 0.13.2## Troubleshooting

- WordCloud

Jika mendapat error saat pertama kali menjalankan:

### Frontend```bash

- HTML5 + CSS3 + JavaScript# Install ulang NLTK data

- LocalStorage untuk historypython -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"

- Custom CSS (Bootstrap-like)```



---## Lisensi



## ğŸ“¦ InstalasiProject ini dibuat untuk keperluan internal BPS.


### 1. Clone Repository
```bash
git clone <repository-url>
cd yt_scraping
```

### 2. Buat Virtual Environment
```bash
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Setup YouTube API Key
Buat file `.env`:
```env
YOUTUBE_API_KEY=your_api_key_here
```

---

## ğŸš€ Cara Penggunaan

### 1. Jalankan Server
```bash
python app.py
```
Server: `http://127.0.0.1:5000`

### 2. Scraping Komentar
1. Buka homepage
2. Paste URL video YouTube
3. Pilih jumlah komentar
4. Klik "Scrape Komentar"

### 3. Analisis Sentimen
1. Pilih metode analisis (Naive Bayes, SVM, LSTM, IndoBERT)
2. Klik "Analisis Sentimen"
3. Tunggu proses selesai (1-3 menit)

### 4. Lihat Hasil
- Statistik sentimen per metode
- Akurasi & confusion matrix
- Word clouds
- Detail komentar

### 5. Quick Analysis
1. Klik "ğŸ’¬ Coba Sekarang" di navbar
2. Ketik komentar
3. Analisis instant dengan 4 metode
4. Simpan ke history

### 6. Detail Preprocessing
1. Buka "Semua Komentar"
2. Klik "ğŸ”¬ Lihat Proses" di komentar
3. Lihat 12 steps preprocessing dalam modal

---

## ğŸ“ Struktur Project

```
yt_scraping/
â”œâ”€â”€ app.py                          # Main Flask app
â”œâ”€â”€ youtube_scraper.py              # YouTube API scraper
â”œâ”€â”€ sentiment_analyzer.py           # Orchestrator
â”œâ”€â”€ ml_sentiment_analyzer.py        # ML methods
â”œâ”€â”€ text_preprocessor.py            # Text preprocessing
â”œâ”€â”€ data_storage.py                 # Storage utilities
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ .env                            # API key
â”œâ”€â”€ README.md                       # Documentation
â”‚
â”œâ”€â”€ templates/                      # HTML files
â”‚   â”œâ”€â”€ base.html
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ analysis.html
â”‚   â”œâ”€â”€ comments.html
â”‚   â”œâ”€â”€ comparison.html
â”‚   â””â”€â”€ about.html
â”‚
â”œâ”€â”€ kamus/                          # Lexicon (22,278 words)
â”‚   â”œâ”€â”€ positive.tsv
â”‚   â”œâ”€â”€ negative.tsv
â”‚   â”œâ”€â”€ sentiwords_id.txt
â”‚   â”œâ”€â”€ boosterwords_id.txt
â”‚   â”œâ”€â”€ negatingword.txt
â”‚   â””â”€â”€ ... (14+ files)
â”‚
â”œâ”€â”€ data/                           # Scraped data
â””â”€â”€ analyses/                       # Analysis results
```

---

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Homepage |
| GET | `/analysis` | Analysis page |
| GET | `/comments` | Comments page |
| POST | `/scrape` | Scrape comments |
| POST | `/analyze` | Analyze sentiment |
| POST | `/analyze_single` | Quick analysis |
| POST | `/preprocess_text` | Get preprocessing steps |
| POST | `/generate_wordcloud` | Generate word clouds |
| GET | `/download_excel` | Export to Excel |

---

## ğŸ” Preprocessing Pipeline

```
Original Text
    â†“ Case Folding
    â†“ Noise Removal
    â†“ Remove Numbers
    â†“ Remove Punctuation
    â†“ Spelling Correction
    â†“ Tokenization
    â†“ Normalization
    â†“ Stopword Removal
    â†“ Stemming
    â†“ Negation Handling
Final Result
```

**Contoh:**
- Input: `"Videonya bagus bgttt!!! ğŸ‘ğŸ˜Š"`
- Output: `"video bagus"`
- Reduction: ~85%

---

## ğŸ“š Lexicon Database

### Total: 22,278 words

- **Positive:** 7,213 words
- **Negative:** 13,214 words
- **Weighted Sentiwords:** 1,729
- **Booster Words:** 30
- **Negation Words:** 10
- **Idioms:** 92
- **Stopwords:** 758
- **Colloquial Lexicon:** 3,600+

---

## ğŸ¯ Performance

### Processing Speed (100 comments):
- Scraping: ~3-5s
- Preprocessing: ~2-3s
- ML Analysis: ~1-2s
- Total: ~6-10s

### Memory Usage:
- Lexicon: ~5MB
- Models: ~10MB
- Total: ~20MB

---

## ğŸ› Known Limitations

1. **LSTM & IndoBERT**: Placeholder implementation
2. **YouTube API Quota**: 10,000 units/day limit
3. **Lexicon Coverage**: Limited to 22K words
4. **LocalStorage**: Max 20 items history

---

## ğŸ”® Future Plans

- [ ] Full LSTM implementation
- [ ] Real IndoBERT integration
- [ ] Real-time analysis
- [ ] Database integration
- [ ] Docker deployment
- [ ] PDF export
- [ ] User authentication

---

## ğŸ“„ License

MIT License

---

## ğŸ“ Contact

For questions or issues:
- Email: your.email@example.com
- GitHub: github.com/yourusername

---

**Last Updated:** October 7, 2025  
**Status:** âœ… Production Ready

ğŸ‰ **Happy Analyzing!** ğŸ‰
